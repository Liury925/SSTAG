from functools import partial
from datasets_process import *
from tasks import *

DATASET_TO_CLASS_DICT = {
    "cora": Cora,
    "pubmed": Pubmed,
    "wikics": WikiCS,
    "arxiv": Arxiv,
    "fb15k237": FB15K237,
    "wn18rr": WN18RR,
    "products": Products,
    "ml1m": ML1M,
    "expla_graph": ExplaGraph,
    "scene_graph": SceneGraph,
    "wiki_graph": WikiGraph,
    "ultrachat200k": UltraChat200k,
    **{name: partial(Chembl, name=name) for name in ["hiv", "pcba", "bbbp", "bace", "cyp450", "muv","esol","freesolv","lipo"]}
}


DATASET_INFOR_DICT = {
    "cora": {"dataset": "cora"},
    "pubmed": {"dataset": "pubmed"},
    "arxiv": {"dataset": "arxiv"},

    #节点分类
    "cora_node": {"dataset": "cora",
                  "task": {"default": DefaultNPTask,
                           "subgraph": SubgraphNPTask,
                           "default_text": DefaultTextNPTask,
                           "subgraph_text": SubgraphTextNPTask,
                           "QA": NQATask},
                  "evaluation": {"default": ("accuracy", {"metric_name": "accuracy", "num_classes": 7}),
                                 "QA": ("text_accuracy",  {"metric_name": "text_accuracy"})},
                  },
    "pubmed_node": {"dataset": "pubmed",
                    "task": {"default": DefaultNPTask,
                             "subgraph": SubgraphNPTask,
                             "default_text": DefaultTextNPTask,
                             "subgraph_text": SubgraphTextNPTask,
                             "QA": NQATask},
                    "evaluation": {"default": ("accuracy", {"metric_name": "accuracy", "num_classes": 3}),
                                   "QA": ("text_accuracy", {"metric_name": "text_accuracy"})},
                    },
    "arxiv_node": {"dataset": "arxiv",
              "task": {"default": DefaultNPTask,
                       "subgraph": SubgraphNPTask,
                       "default_text": DefaultTextNPTask,
                       "subgraph_text": SubgraphTextNPTask,
                       "QA": NQATask},
              "evaluation": {"default": ("accuracy", {"metric_name": "accuracy", "num_classes": 40}),
                             "QA": ("text_accuracy", {"metric_name": "text_accuracy"})},
              },
    "wikics": {"dataset": "wikics",
               "task": {"default": DefaultNPTask,
                        "subgraph": SubgraphNPTask,
                        "default_text": DefaultTextNPTask,
                        "subgraph_text": SubgraphTextNPTask,
                        "QA": NQATask},
               "evaluation": {"default": ("accuracy", {"metric_name": "accuracy", "num_classes": 10}),
                              "QA": ("text_accuracy", {"metric_name": "text_accuracy"})},
               },
    "products": {"dataset": "products",
                 "task": {"default": DefaultNPTask,
                          "subgraph": SubgraphNPTask,
                          "default_text": DefaultTextNPTask,
                          "subgraph_text": SubgraphTextNPTask,
                          "QA": NQATask},
                 "evaluation": {"default": ("accuracy", {"metric_name": "accuracy", "num_classes": 44}),
                                "QA": ("text_accuracy", {"metric_name": "text_accuracy"})},
                 },


    #链接预测
    "cora_link": {"dataset": "cora",
                  "task": {"default": DefaultLPTask,
                           "subgraph": SubgraphLPTask,
                           "default_text": DefaultTextLPTask,
                           "subgraph_text": SubgraphTextLPTask,
                           "QA": LQATask},
                  "evaluation": {"default": ("accuracy", {"metric_name": "accuracy", "num_classes": 2}),
                                 "QA": ("text_accuracy", {"metric_name": "text_accuracy", "mode": "re",
                                                          "regular_patterns": r"\b(Yes|yes|No|no)\b"})},
                  },
    "pubmed_link": {"dataset": "pubmed",
                    "task": {"default": DefaultLPTask,
                             "subgraph": SubgraphLPTask,
                             "default_text": DefaultTextLPTask,
                             "subgraph_text": SubgraphTextLPTask,
                             "QA": LQATask},
                    "evaluation": {"default": ("accuracy", {"metric_name": "accuracy", "num_classes": 2}),
                                   "QA": ("text_accuracy", {"metric_name": "text_accuracy", "mode": "re",
                                                          "regular_patterns": r"\b(Yes|yes|No|no)\b"})},
                    },
    "arxiv_link": {"dataset": "arxiv",
                   "task": {"default": DefaultLPTask,
                            "subgraph": SubgraphLPTask,
                            "default_text": DefaultTextLPTask,
                            "subgraph_text": SubgraphTextLPTask,
                            "QA": LQATask},
                   "evaluation": {"default": ("accuracy", {"metric_name": "accuracy", "num_classes": 2}),
                                  "QA": ("text_accuracy", {"metric_name": "text_accuracy", "mode": "re",
                                                           "regular_patterns": r"\b(Yes|yes|No|no)\b"})},
                   },
    "fb15k237": {"dataset": "fb15k237",
                 "task": {"default": DefaultLPTask,
                          "subgraph": SubgraphLPTask,
                          "default_text": DefaultTextLPTask,
                          "subgraph_text": SubgraphTextLPTask,
                          "QA": LQATask},
                 "evaluation": {"default": ("accuracy", {"metric_name": "accuracy", "num_classes": 237}),
                                "QA": ("text_accuracy", {"metric_name": "text_accuracy"})},
                 },
    "wn18rr": {"dataset": "wn18rr",
               "task": {"default": DefaultLPTask,
                        "subgraph": SubgraphLPTask,
                        "default_text": DefaultTextLPTask,
                        "subgraph_text": SubgraphTextLPTask,
                        "QA": LQATask},
               "evaluation": {"default": ("accuracy", {"metric_name": "accuracy", "num_classes": 11}),
                              "QA": ("text_accuracy", {"metric_name": "text_accuracy"})},
               },
    "ml1m": {"dataset": "ml1m",
             "task": {"default": DefaultLPTask,
                      "subgraph": SubgraphLPTask,
                      "default_text": DefaultTextLPTask,
                      "subgraph_text": SubgraphTextLPTask,
                      "QA": LQATask},
             "evaluation": {"default": ("rmse", {"metric_name": "rmse"}),
                            "QA": ("text_rmse", {"metric_name": "text_rmse"})},
             },

    #图分类
    "hiv": {"dataset": "hiv",
            "task": {"default": DefaultGPTask,
                     "default_text": DefaultTextGPTask,
                     "QA": GQATask},
            "evaluation": {"default": ("auc", {"metric_name": "auc"}),
                           "QA": ("text_accuracy", {"metric_name": "text_accuracy", "mode": "re",
                                                          "regular_patterns": r"\b(Yes|yes|No|no)\b"})},
            },
    "pcba": {"dataset": "pcba",
             "task": {"default": DefaultGPTask,
                      "default_text": DefaultTextGPTask,
                      "QA": GQATask},
             "evaluation": {"default": ("apr", {"metric_name": "apr", "num_labels": 128}),
                            "QA": ("text_accuracy", {"metric_name": "text_accuracy", "mode": "re",
                                                          "regular_patterns": r"\b(Yes|yes|No|no)\b"})},
             },
    "bbbp": {"dataset": "bbbp",
             "task": {"default": DefaultGPTask,
                      "default_text": DefaultTextGPTask,
                      "QA": GQATask},
             "evaluation": {"default": ("auc", {"metric_name": "auc"}),
                            "QA": ("text_accuracy", {"metric_name": "text_accuracy", "mode": "re",
                                                          "regular_patterns": r"\b(Yes|yes|No|no)\b"})},
             },
    "bace": {"dataset": "bace",
             "task": {"default": DefaultGPTask,
                      "default_text": DefaultTextGPTask,
                      "QA": GQATask},
             "evaluation": {"default": ("auc", {"metric_name": "auc"}),
                            "QA": ("text_accuracy", {"metric_name": "text_accuracy", "mode": "re",
                                                          "regular_patterns": r"\b(Yes|yes|No|no)\b"})},
             },

    "cyp450": {"dataset": "cyp450",
               "task": {"default": DefaultGPTask,
                        "default_text": DefaultTextGPTask,
                        "QA": GQATask},
               "evaluation": {"default": ("multiauc", {"metric_name": "multiauc", "num_labels": 5}),
                              "QA": ("text_accuracy", {"metric_name": "text_accuracy", "mode": "re",
                                                       "regular_patterns": r"\b(Yes|yes|No|no)\b"})},
               },
    "muv": {"dataset": "muv",
            "task": {"default": DefaultGPTask,
                     "default_text": DefaultTextGPTask,
                     "QA": GQATask},
            "evaluation": {"default": ("multiauc", {"metric_name": "multiauc", "num_labels": 17}),
                           "QA": ("text_accuracy", {"metric_name": "text_accuracy", "mode": "re",
                                                    "regular_patterns": r"\b(Yes|yes|No|no)\b"})},
            },

    ##图回归
    "esol": {"dataset": "esol",
             "task": {"default": DefaultGPTask,
                      "default_text": DefaultTextGPTask,
                      "QA": GQATask},
             "evaluation": {"default": ("rmse", {"metric_name": "rmse"}),
                            "QA": ("text_rmse", {"metric_name": "text_rmse"})},
             },
    "freesolv": {"dataset": "freesolv",
                 "task": {"default": DefaultGPTask,
                          "default_text": DefaultTextGPTask,
                          "QA": GQATask},
                 "evaluation": {"default": ("rmse", {"metric_name": "rmse"}),
                                "QA": ("text_rmse", {"metric_name": "text_rmse"})},
                 },
    "lipo": {"dataset": "lipo",
             "task": {"default": DefaultGPTask,
                      "default_text": DefaultTextGPTask,
                      "QA": GQATask},
             "evaluation": {"default": ("rmse", {"metric_name": "rmse"}),
                            "QA": ("text_rmse", {"metric_name": "text_rmse"})},
             },

    #问答
    "expla_graph": {"dataset": "expla_graph",
                    "task": {"default_text": DefaultTextGPTask,
                             "QA": GQATask},
                    "evaluation": {"default": ("accuracy", {"metric_name": "accuracy", "num_classes": 2}),
                                   "QA": ("text_accuracy", {"metric_name": "text_accuracy", "mode": "re",
                                                            "regular_patterns": r"\b(Support|support|Counter|counter)\b"})},
                    },
    "scene_graph": {"dataset": "scene_graph",
                    "task": {"QA": GQATask},
                    "evaluation": {"QA": ("text_accuracy", {"metric_name": "text_accuracy", "mode": "search"})},
                    },
    "wiki_graph": {"dataset": "wiki_graph",
                    "task": {"QA": GQATask},
                    "evaluation": {"QA": ("text_accuracy", {"metric_name": "text_accuracy"})},
                    },
    "ultrachat200k": {"dataset": "ultrachat200k",
                    "task": {"QA": GQATask},
                    "evaluation": {"QA": ("text_accuracy", {"metric_name": "text_accuracy"})},
                    },

}